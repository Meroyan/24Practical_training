{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167d7be2-b552-4d85-829a-2dc35037da38",
   "metadata": {},
   "source": [
    "# 构建聊天机器人\n",
    "## 概述\n",
    "\n",
    "我们将介绍一个示例，说明如何设计和实现基于 LLM 的聊天机器人。该聊天机器人将能够进行对话并记住之前的互动。\n",
    "\n",
    "## 概念\n",
    "\n",
    "以下是我们将要使用的一些高级组件：\n",
    " - Chat Models聊天模型。\n",
    " - Prompt Templates提示模板，简化了组合提示的过程，这些提示结合了默认消息、用户输入、聊天历史记录和（可选）其他检索到的上下文。\n",
    " - Chat History聊天历史记录，允许聊天机器人“记住”过去的互动，并在回答后续问题时将其考虑在内。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ad4a08-27e8-42d7-86b9-95166dfd450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a2300-079a-47ce-9506-84c2631fc622",
   "metadata": {},
   "source": [
    "# 获取你的智谱 API Key\n",
    "在当前文件下创建一个.env文件，将api-key复制进去，如ZHIPUAI_API_KEY = \"api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a831f5d0-c424-424a-86c6-c46201443a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6d99f-5076-4792-9c65-3d62b3cdaab4",
   "metadata": {},
   "source": [
    "# Using Language Models\n",
    "\n",
    "首先，让我们学习如何单独使用语言模型。LangChain 支持多种不同的语言模型，您可以互换使用 - 在下面选择您想要使用的模型！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709b4225-7650-4d68-8413-860434a82577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.chat_models import ChatBaichuan\n",
    "\n",
    "# model = ChatBaichuan(\n",
    "#     temperature=0.5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0240bc-a178-4d21-8f15-b431f71a4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.baichuan-ai.com/v1\",\n",
    "#     api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "#     model=\"Baichuan3-Turbo\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d948518a-cd98-4285-b4c7-58598837cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "model = ChatZhipuAI(\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    model=\"glm-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac74105-0620-49b0-8228-b783f79b29bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，张三！有什么可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 11, 'total_tokens': 23}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-efa72c1a-795b-4c98-8b1b-6bb74dd7ba50-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"你好，我叫张三。\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf13a88-bff8-4829-bb5b-67382a7eb587",
   "metadata": {},
   "source": [
    "让我们首先直接使用该模型。ChatModel 是 LangChain“Runnable”的实例，这意味着它们公开了一个用于与其交互的标准接口。为了简单地调用该模型，我们可以将消息列表传递给 .invoke 方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846242e0-8ead-4bb0-bc9e-4db8af2ebbf9",
   "metadata": {},
   "source": [
    "模型本身没有任何状态概念。例如，如果你问一个后续问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6b715d-ee49-4309-9cd5-8b2052d75368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='作为一个AI，我无法知道您的名字，除非您告诉我。如果您愿意分享，请告诉我您的名字，我会很高兴认识您。', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 8, 'total_tokens': 37}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-1a930493-e3d4-4a92-9bb4-98f455a08372-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"我的名字是什么\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b75477-3160-4c3d-a001-02f5fa54e7f1",
   "metadata": {},
   "source": [
    "为了解决这个问题，我们需要将整个对话历史记录传递到模型中。让我们看看这样做会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5db015-ca34-43bf-8305-71ac2244c44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你的名字是张三。有什么问题我可以帮你解答吗？', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 29, 'total_tokens': 43}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-a66c1a3a-135a-4686-8e5b-a62285104a19-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"你好！我是张三\"),\n",
    "    AIMessage(content=\"你好，张三！请问有什么我可以帮到你的吗？\"),\n",
    "    HumanMessage(content=\"我的名字是什么\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1279718-1b6c-483a-82ee-03b1c3acbb24",
   "metadata": {},
   "source": [
    "现在我们可以看到我们得到了很好的回应！  \n",
    "\n",
    "这是聊天机器人对话式互动能力的基本理念。那么我们如何才能最好地实现这一点呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93230a-e490-4133-9ffa-597c1ecba564",
   "metadata": {},
   "source": [
    "## Message History-消息历史记录\n",
    "\n",
    "我们可以使用消息历史记录类来包装我们的模型并使其具有状态。这将跟踪模型的输入和输出，并将它们存储在某个数据存储中。未来的交互将加载这些消息并将它们作为输入的一部分传递到链中。让我们看看如何使用它！  \n",
    "\n",
    "我们可以导入相关类并设置我们的链，该链包装模型并添加此消息历史记录。这里的关键部分是我们作为 get_session_history 传递的函数。此函数应接受 session_id 并返回消息历史记录对象。此 session_id 用于区分单独的对话，应在调用新链时作为配置的一部分传入（我们将展示如何做到这一点）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1655f699-fa27-41b2-9f7c-1666cd67d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84623285-5f70-43c9-a446-f8e50fdf44a2",
   "metadata": {},
   "source": [
    "现在我们需要创建一个配置，每次将其传递给可运行程序。此配置包含不直接属于输入但仍然有用的信息。在本例中，我们希望包含一个 session_id。这应该如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7671ba-7b06-411d-b3d5-b619a5702657",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c8fe669-64f0-47df-ba1a-bc31ffafc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，张三！有什么可以帮助你的吗？'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好！我是张三\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08e6812d-cda6-49bf-a7af-3ddeda61a9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你的名字是张三。如果有其他问题，我会尽力帮助你。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b1e32-8641-4773-82e4-e419a9f871f7",
   "metadata": {},
   "source": [
    "太棒了！我们的聊天机器人现在可以记住我们的事情了。如果我们更改配置以引用不同的 session_id，我们可以看到它会重新开始对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e227b7-886e-49f8-8e27-47e461d5cc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'作为人工智能助手，我没有办法知道您的名字。除非您在之前的对话中告诉过我，或者您提供一个上下文使得我能够推断出您的名字。如果您愿意，可以告诉我您的名字，我会记录在本次对话中以便使用。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f07d8-6489-4133-8b23-57af5cf70e32",
   "metadata": {},
   "source": [
    "但是，我们总是可以回到原始对话（因为我们将其保存在数据库中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606a118a-1010-418a-840c-0c04af2780d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你之前提到你的名字是张三。如果这是一个测试或者你有其他问题，请告诉我。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c5974-3d71-4281-bcba-95c1d7c64882",
   "metadata": {},
   "source": [
    "这就是我们如何支持聊天机器人与许多用户进行对话！  \n",
    "\n",
    "现在，我们所做的只是在模型周围添加一个简单的持久层。我们可以通过添加提示模板来开始使其变得更加复杂和个性化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18c7c-702c-4293-8b1a-eb3a3806798a",
   "metadata": {},
   "source": [
    "## Prompt templates-提示模板\n",
    "\n",
    "提示模板有助于将原始用户信息转换为 LLM 可以使用的格式。在这种情况下，原始用户输入只是一条消息，我们将其传递给 LLM。现在让我们让它更复杂一点。首先，让我们添加一条带有一些自定义指令的系统消息（但仍然将消息作为输入）。接下来，除了消息之外，我们还将添加更多输入。  \n",
    "\n",
    "首先，让我们添加一条系统消息。为此，我们将创建一个 ChatPromptTemplate。我们将利用 MessagesPlaceholder 传递所有消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b768eac7-7027-4abe-9e16-1a93aa79c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一位乐于助人的助手。尽你所能回答所有问题。\"),\n",
    "        # (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d4e86-11c6-49e8-b2aa-ef156fdb539d",
   "metadata": {},
   "source": [
    "请注意，这会稍微改变输入类型 - 而不是传递消息列表，现在我们传递一个带有消息键的字典，其中包含消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e8965a0-49d4-4513-9d64-23494351c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很高兴见到你！作为一位乐于助人的助手，我随时准备回答你的问题或帮助你解决问题。有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"你好！我是王五\")]\n",
    "})\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe397ce0-a486-429f-8935-d18a6ca5f5ad",
   "metadata": {},
   "source": [
    "我们现在可以将其包装在与之前相同的消息历史记录对象中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70dedccc-bef5-4824-81be-19780051cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39866a00-048c-4fe8-9b2b-7d40011c6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc5\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45501bb8-0c78-416c-b482-e0cc4c170557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很高兴见到你，赵六！如果你有任何问题或需要帮助，请随时告诉我，我会尽我所能为你提供帮助。现在，有什么我可以帮您的吗？'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好！我是赵六\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71ea20a-bf1a-4263-bc03-9d539ce2bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1639746b-1974-4794-988f-77fae9ced8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'抱歉，作为一个人工智能助手，我没有访问您个人信息的能力，因此我不知道您的名字。如果您愿意告诉我，我可以使用您提供的名字来与您交流。'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e782910-6a6d-4e58-82bd-0368a94a6e01",
   "metadata": {},
   "source": [
    "太棒了！现在让我们把提示变得更复杂一点。假设提示模板现在看起来像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02fce9a9-e63c-4e8b-9ac0-686f5a4092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个乐于助人的助手。请用{language}回答所有问题.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b0165-b477-4c44-81d1-4a63aca28a41",
   "metadata": {},
   "source": [
    "请注意，我们在提示中添加了新的language输入。现在我们可以调用链并传入我们选择的语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00925ae2-7bcb-43c4-9a9a-b6b9ff992cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'はい、お手伝いできることがあれば、どうぞお知らせください。何をお困りでしょうか？ お手伝いできることがありましたら、日本語で答えます。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"你好！我是张三\")],\n",
    "    \"language\":\"日文\",\n",
    "})\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e811d3c-dc24-4f10-9a81-4bbc6d234cff",
   "metadata": {},
   "source": [
    "现在让我们将这个更复杂的链包装到 Message History 类中。这一次，由于输入中有多个键，我们需要指定用于保存聊天记录的正确键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cdc4480-402f-436e-8d63-d9be6e456ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7b8bc05-20b1-4a60-a06b-192bffb293f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc6\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6696bb0-623c-41e3-b892-f071fe058caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! I'm here to help. How can I assist you today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"你好,我是张小三。\")],\"language\":\"英语\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffad5ca0-6a87-418f-9a56-be1cf449f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 저는 장小三입니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"你好,我是张小三。\")],\"language\":\"韩文\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc4036-1cb3-4faf-b0d6-bdea18b4ca4d",
   "metadata": {},
   "source": [
    "# Managing Conversation History - 管理对话历史记录\n",
    "\n",
    "构建聊天机器人时需要理解的一个重要概念是如何管理对话历史记录。如果不加以管理，消息列表将无限制增长，并可能溢出 LLM 的上下文窗口。因此，添加一个限制传入消息大小的步骤非常重要。  \n",
    "\n",
    "重要的是，您需要在提示模板之前但在从消息历史记录中加载以前的消息之后执行此操作。  \n",
    "\n",
    "我们可以通过在提示前面添加一个简单的步骤来适当修改消息键，然后将该新链包装在消息历史记录类中来实现这一点。首先，让我们定义一个将修改传入消息的函数。让我们让它选择最近的 k 条消息。然后我们可以通过在开头添加它来创建一个新链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75adf47d-21e4-4994-a8e9-83e84b87c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个乐于助人的助手。请尽力回答所有问题并用{language}翻译.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def filter_messages(messages,k=10):\n",
    "    return messages[-k:]\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=lambda x: filter_messages(x[\"messages\"]))\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28154157-d983-465e-a127-b2b905b63733",
   "metadata": {},
   "source": [
    "现在让我们尝试一下！如果我们创建一个超过 10 条消息的列表，我们可以看到它不再记住早期消息中的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "138beefe-14aa-453c-8cc6-990d219926f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"你好，我是王小五\"),\n",
    "    AIMessage(content=\"你好!\"),\n",
    "    HumanMessage(content=\"我喜欢吃香草冰淇凌\"),\n",
    "    AIMessage(content=\"你的品味不错\"),\n",
    "    HumanMessage(content=\"2+2等于多少\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"谢谢\"),\n",
    "    AIMessage(content=\"不客气!\"),\n",
    "    HumanMessage(content=\"玩得开心吗?\"),\n",
    "    AIMessage(content=\"是的!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "157ed5f2-7b84-4754-b9c5-958a339464f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have the ability to know your name unless you've told me before. If you haven't shared your name, I can't provide it. What would you like me to call you? \\n\\n(Translation: As an AI, I don't have the capability to know your name unless you've informed me previously. If you haven't revealed your name, I cannot provide it. What name would you like me to address you by?)\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"我叫什么?\")],\n",
    "        \"language\": \"英文\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ebb5761-0d38-4eb7-95c8-3f98b57606c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据你提供的信息，你没有直接提到你最喜欢的冰淇凌口味。但是，如果你喜欢香草冰淇凌，那么可以假设香草是你最爱的口味。这是基于以下信息：\\n\\n\"5. 标题：什么口味的冰淇凌最受欢迎\\n摘要：我听说懂得欣赏冰淇淋的人都吃香草味的\\n奶油味的还是可以的\\n所以一般情况下我都是吃香草味和奶油味两样一起的\"\\n\\n如果这段信息反映的是你的喜好，那么香草味可能是你最喜欢的冰淇凌口味之一。如果你有其他更具体的口味喜好，请告诉我，我会更新我的答案。'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"我最爱的冰淇凌口味是哪种？\")],\n",
    "        \"language\": \"英文\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df9d4d-75fe-45be-bbc5-0143504704cc",
   "metadata": {},
   "source": [
    "# Streaming - 流媒体\n",
    "\n",
    "现在我们有了一个功能聊天机器人。但是，聊天机器人应用程序的一个非常重要的用户体验考虑因素是流式传输。LLM 有时可能需要一段时间才能响应，因此为了改善用户体验，大多数应用程序都会在生成每个令牌时将其流式传输回来。这允许用户查看进度。  \n",
    "\n",
    "其实这样做非常简单！  \n",
    "\n",
    "所有链都公开一个 .stream 方法，使用消息历史记录的链也不例外。我们可以简单地使用该方法来获取流式响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a3366cb-8d1c-4725-aa62-6d53baaf5d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'httpx_sse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabc7\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m     }\n\u001b[0;32m      5\u001b[0m }\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwith_message_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m你好，我是赵小六，给我讲个笑话吧。\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m英文\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4761\u001b[0m, in \u001b[0;36mRunnableBindingBase.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   4756\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4758\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4759\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4760\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 4761\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   4762\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4764\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4765\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4761\u001b[0m, in \u001b[0;36mRunnableBindingBase.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   4756\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4758\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4759\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4760\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 4761\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   4762\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4764\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4765\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   2878\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2879\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2881\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2882\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2883\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2870\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   2865\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2866\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   2867\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2868\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2869\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2870\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   2871\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   2873\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   2874\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2875\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1868\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1868\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   1870\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2832\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   2829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2830\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 2832\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_pipeline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1181\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\branch.py:325\u001b[0m, in \u001b[0;36mRunnableBranch.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbranch:default\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output_supported\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4761\u001b[0m, in \u001b[0;36mRunnableBindingBase.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   4756\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4758\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4759\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4760\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 4761\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   4762\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4764\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4765\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   2878\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2879\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2881\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2882\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2883\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2870\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   2865\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2866\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   2867\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2868\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2869\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2870\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   2871\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   2873\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   2874\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2875\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1868\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1868\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mnext\u001b[39m, iterator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   1870\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2832\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   2829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2830\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 2832\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_pipeline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1181\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:343\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    337\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[0;32m    338\u001b[0m         e,\n\u001b[0;32m    339\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[0;32m    340\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    341\u001b[0m         ),\n\u001b[0;32m    342\u001b[0m     )\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:323\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_community\\chat_models\\zhipuai.py:478\u001b[0m, in \u001b[0;36mChatZhipuAI._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mClient(headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[1;32m--> 478\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconnect_sse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzhipuai_api_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent_source\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_sse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Miniconda\\envs\\ai_learn\\Lib\\site-packages\\langchain_community\\chat_models\\zhipuai.py:56\u001b[0m, in \u001b[0;36mconnect_sse\u001b[1;34m(client, method, url, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect_sse\u001b[39m(client: Any, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for connecting to an SSE stream.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        The event source.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttpx_sse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventSource\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client\u001b[38;5;241m.\u001b[39mstream(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m EventSource(response)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'httpx_sse'"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc7\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"你好，我是赵小六，给我讲个笑话吧。\")],\n",
    "        \"language\":\"英文\"\n",
    "    },\n",
    "    config=config\n",
    "):\n",
    "    print(r.content,end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8524e-7a55-4739-a4ca-01d74e3fc502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
